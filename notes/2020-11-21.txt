Events:
- Had a call with supervisor, Vinay.

- From ^, introduced to tacotron2!

- Got the published model by NVIDIA working for tacotron2.

- Looked into LibriVox, a catalog of open audiobooks, and Project Gutenbeg, a database of open ebooks.

- Developed scripts to split an an audiobook into many .wav files and an ebook into many .txt files.

- Proposed the idea of using ^ to form training (and testing) data for new tacotron2 models; which could be used for non-narrator voices.


Thoughts:

- Narration, or the main voice, would be done by the open, NVIDIA published, model as its so good.

- Would need another ~10 voices, I think:
  - Requires either the sourcing of open trained tacotron2 models, or training my own models.
  - Can train own models using the combination of a reader's open audiobooks and their respective ebooks, chunked by my scripts.
  Issues:
  - No idea how much data is required for a good, believable, model/voice.
    - Amount of data is likely not the problem, breaking the data down into perfectly tagged, supervised, data is.
  - This idea for training, whilst good due to a large catalog of data per reader/voice, will require manual supervision of the chunks.
    - At current, my scripts are not accurate in matching the chunks, similar number of chunks, but text chunk often does not match its audio chunk.
      - Requires manually going through and adjusting each text chunks to match the audio chunks.
      - Will require manual supervision regardless, to assure chunks are correct for proper training.
      - Scripts can probably be further improved to lessen manual overhead.

- Need a way of selecting a voice for dialog:
  - Current thought is to form the ~10 models and then using a survey to get feedback on what descriptors are good for each model/voice.
    - Have the ability to select from some shared, common, descriptors and then a free field to enter any descriptors they feel appropriate.
  - Then, train a simple NN to take in descriptors and output a ranked suggestion of the voices, using the survey results.
  - Then, take a list of the speaking characters, ordered by how often they are mentioned, and run them through the voice-selector NN.
    - This would pick a unique voice for each character, based on any descriptors used for that character.
      - If two sets of descriptors pick the same voice, the character with the most dialogue gets the voice and the other gets the next best.
  Issues:
  - Have no way (yet) of linking dialogue to named entities, which is essential.
  - Have no way (yet) of linking descriptors to named entities, which is also essential.
  - Requires a survey, which requires the models to be trained before giving out the survey.
    - This is therefore reliant on having multiple, trained, tacotron2 TTS models - extremely time and resource consuming.


Closing:
- Honestly, this is such a cool idea and system. But it's massive and ambitious.

- Could probably do with lowering the focus and providing just a proof-of-concept of each part. (Maybe running with this to pursue a PhD???).
  - Proof-of-concept the training of a model via audiobook+ebook combination.
  - Proof-of-concept the selection of voice based on descriptors.
    - Could be done with just normal, human, voice recordings and having a survey based on those which trains a selection NN.
  - Proof-of-concept the speaking character and descriptors collection.
  - Proof-of-concept the audio-stitching to form one audiobook.

- Parts that are left over that still need to be, at least theoretically, thought out:
  - Method of linking dialogue to named entities.
  - Method of linking descriptors of entities to their entities.
  - Stitching together multiple audio files to form one audio file, aka audiobook. (Narration, dialogue, narration, other dialogue, etc..).





Entire system:

Trained voice models:
  - Narrator, aka voice_0; aka open, NVIDIA published, tacotron2 model.
  - As many other voices as possible:
    - Source open, trained tacotron2, models from wherever possible.
    - Train own models using combination of open audiobooks and their respective open ebooks, requires somewhat manual supervision of data.

Ebook analyser:
  - Analyse ebook's text; pulling out named entities, their dialogue, and their descriptors.
  - Store sequential list of text spoken by whom: narrator or voice.

Voice selector:
  - Take in list of descriptors and output ranked list of best-guess voices.
  - Pick a unique, best-guess, voice for each character, prioritised by amount of dialogue.
  - Trained on results from survey on descriptor tagging of the trained voices.

Audio synthesiser:
  - Take in text and a trained tacotron2 model, output audio file of TTS.
  - Stitch together a list of audio files into one file; do so in given order, with small breaks in between each file.
